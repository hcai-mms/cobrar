experiment:
  dataset: m4a
  models:
    external.VBPR:
      meta:
        hyper_opt_alg: grid
        verbose: False
        save_weights: False
        save_recs: False
        validation_rate: 1
        validation_metric: nDCG@10
        restore: False
      lr: [ 0.0001, 0.0005, 0.001, 0.005, 0.01 ]
      modalities: [('emotion'), ('textual'), ('audio'), ('visual')]
      epochs: 200
      factors: 64
      batch_size: 1024
      l_w: [ 1e-5, 1e-2 ]
      comb_mod: concat
      seed: 123
      early_stopping:
        patience: 5
        monitor: nDCG@10
    external.MMGCN:
      meta:
        hyper_opt_alg: grid
        verbose: True
        save_weights: False
        save_recs: False
        validation_rate: 1
        validation_metric: nDCG@10
        restore: False
      lr: [ 0.00001, 0.00003, 0.0001, 0.001, 0.01 ]
      epochs: 200
      num_layers: 3
      factors: 64
      factors_multimod: (256, None)
      batch_size: 1024
      aggregation: mean
      concatenation: False
      has_id: True
      modalities: [('emotion'), ('textual'), ('audio'), ('visual')]
      l_w: [ 1e-5, 1e-2 ]
      seed: 123
      early_stopping:
        patience: 5
        monitor: nDCG@10