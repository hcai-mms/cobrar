experiment:
  backend: pytorch
  data_config:
    strategy: dataset
    dataset_path: ../data/{0}/interactions.tsv
    side_information:
      - dataloader: VisualAttribute
        visual_features: ../data/{0}/visual_embeddings/resnet
      - dataloader: TextualAttribute
        textual_features: ../data/{0}/textual_embeddings/bert
      - dataloader: AudioAttribute
        audio_features: ../data/{0}/audio_embeddings/musicnn
      - dataloader: EmotionAttribute
        emotion_features: ../data/{0}/emotion_embeddings/gems
  dataset: sample
  prefiltering:
    strategy: iterative_k_core
    core: 5
  splitting:
    save_on_disk: True
    save_folder: ../data/{0}/splits
    test_splitting:
      strategy: random_subsampling
      test_ratio: 0.2
    validation_splitting:
      strategy: random_subsampling
      test_ratio: 0.1
  top_k: 20
  evaluation:
    cutoffs: [ 1, 5, 10, 20]
    simple_metrics: [ Recall, Precision, nDCG, HR, EFD, EPC, ARP, PopREO, PopRSP ]
    paired_ttest: False
    wilcoxon_test: False
  gpu: 0
  external_models_path: ../external/models/__init__.py
  models:
    external.VBPR:
      meta:
        hyper_opt_alg: grid
        verbose: False
        save_weights: False
        save_recs: False
        validation_rate: 1
        validation_metric: nDCG@10
        restore: False
      lr: [ 0.0001, 0.0005, 0.001, 0.005, 0.01 ]
      modalities: [('visual',), ('textual', ), ('audio', ), ('emotion', )]
      loaders: ('VisualAttribute', 'TextualAttribute', 'AudioAttribute', 'EmotionAttribute')
      epochs: 200
      factors: 64
      batch_size: 1024
      l_w: [ 1e-5, 1e-2 ]
      comb_mod: concat
      seed: 123
      early_stopping:
        patience: 5
        monitor: nDCG@10
    external.MMGCN:
      meta:
        hyper_opt_alg: grid
        verbose: True
        save_weights: False
        save_recs: False
        validation_rate: 1
        validation_metric: nDCG@10
        restore: False
      lr: [ 0.00001, 0.00003, 0.0001, 0.001, 0.01 ]
      epochs: 200
      num_layers: [1, 2, 3]
      factors: 64
      factors_multimod: (256, None)
      batch_size: 1024
      aggregation: mean
      concatenation: False
      has_id: True
      modalities: [('visual',), ('textual', ), ('audio', ), ('emotion', )]
      loaders: ('VisualAttribute', 'TextualAttribute', 'AudioAttribute', 'EmotionAttribute')
      l_w: [ 1e-5, 1e-2 ]
      seed: 123
      early_stopping:
        patience: 5
        monitor: nDCG@10