experiment:
  backend: pytorch
  data_config:
    strategy: fixed
    train_path: ../data/{0}/train.tsv
    validation_path: ../data/{0}/val.tsv
    test_path: ../data/{0}/test.tsv
    side_information:
       - dataloader: AudioAttribute
         audio_features: ../dataset/{0}/audio_embeddings/maest
  dataset: onion
  top_k: 50
  evaluation:
    cutoffs: [ 20 ]
    simple_metrics: [ Precision, nDCG, HR ]
  gpu: 0
  external_models_path: ../external/models/__init__.py
  models:
    external.SiBraR:
      meta:
        hyper_opt_alg: grid
        verbose: True
        save_weights: False
        save_recs: False
        validation_rate: 1
        validation_metric: nDCG@20
        restore: False
      lr: [ 1e-5, 1e-6 ]
      num_neg: [ 10 ]

      norm_input_feat: [ False ]
      input_dim: [ 1024 ]
      norm_sbra_input: [ False ]
      mid_layers: [ [512, 256], [128], [] ]
      emb_dim: [  128, 64 ]
      # When to apply batch normalization
      # This is batch_norm_every in SiBraR
      # 0 ... deactivate, 1+ ... every n layers, -1 ... only last layer
      # WIP still not working
#      b_norm_e: -1

      item_mods: ('audio', )
      epochs: 50
      w_decay: [  1e-2, 1e-3 ]
      dropout: [ 1e-1, 1e-2 ]
      # use_user_profile i.e., users interactions for embedding users
      u_prof: True
      cl_weight: [ 1.e-6 ]
      cl_temp: [ 1.e-1 ]
      batch_size: 1024
      loaders: ('AudioAttribute', )
      seed: 123
      early_stopping:
        patience: 5
        mode: auto
        monitor: nDCG@20
        verbose: True