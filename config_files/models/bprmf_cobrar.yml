experiment:
  gpu: 0
  backend: pytorch
  models:
    external.BPRMF:
      meta:
        save_weights: False
        save_recs: False
      lr: [ 1.e-2,  1.e-3,  1.e-4,  1.e-5 ] #,  1.e-7,  1.e-6
      batch_size: [  256 ]
      factors: [ 128, 64 ]
      l_w: [  1.e-3,  1.e-2 ]
      # I experience that 200 is too few on onion
      epochs: 500

      early_stopping:
        verbose: False
        patience: 10
        monitor: nDCG@5