experiment:
  backend: pytorch
  models:
    external.DeepMF:
      lr: [ 1.e-4, 1.e-3, 1.e-2 ]
      # todo optimize
      batch_size: [ 512 ]
      reg: [ 1.e-5, 1.e-4, 1.e-3 ]
      embedding_dim: [ 256, 128, 64 ]
      user_mlp: [ [512,  256], [512], [256], [] ]
      item_mlp: [ [512,  256], [512], [256], [] ]
      neg_ratio: [ 5 ]
      similarity: cosine